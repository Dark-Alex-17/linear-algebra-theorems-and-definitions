\section{Inner Products and Norms}

\begin{definition}
	\hfill\\
	Let $V$ be a vector space over $\F$. An \textbf{inner product} on $V$ is a function that assigns, to every ordered pair of vectors $x$ and $y$ in $V$, a scalar in $\F$, denoted by $\lr{x, y}$, such that for all $x, y$ and $z$ in $V$ and all $c$ in $\F$, the following hold:

	\begin{enumerate}
		\item $\lr{x + z, y} = \lr{x, y} + \lr{z,y}$.
		\item $\lr{cx, y} = c\lr{x,y}$.
		\item $\overline{\lr{x,y}} = \lr{y,x}$, where the bar denoted complex conjugation.
		\item $\lr{x, x} > 0$ if $x \neq 0$.
	\end{enumerate}
\end{definition}

\begin{definition}\label{Definition 6.2}
	\hfill\\
	If $x$ and $y$ are in the vector space $\C^n$, define their inner product to be

	\[\lr{x,y} = \sum_{k=1}^{n}x_k\overline{y_k}.\]

	This is called the (complex) \textbf{standard inner product}.\\

	When $\F = \R$ the conjugations are not needed, and in early courses this standard inner product is usually called the \textit{dot product} and is denoted by $x \cdot y$ instead of $\lr{x, y}$.
\end{definition}

\begin{definition}\label{Conjugate Transpose}
	\hfill\\
	Let $A \in M_{m \times n}(\F)$. We define the \textbf{conjugate transpose} or \textbf{adjoint} of $A$ to be the $n \times m$ matrix $A^*$ such that $(A^*)_{ij} = \overline(A_{ij})$ for all $i,j$.
\end{definition}

\begin{definition}\label{Definition 6.4}
	\hfill\\
	Given two complex number-valued $n \times m$ matrices $A$, and $B$, written explicitly as

	\[A = \begin{pmatrix}
			A_{11} & A_{12} & \dots  & A_{1m} \\
			A_{21} & A_{22} & \dots  & A_{2m} \\
			\vdots & \vdots & \ddots & \vdots \\
			A_{n1} & A_{n2} & \dots  & A_{nm}
		\end{pmatrix},\ \ \ \ \begin{pmatrix}
			B_{11} & B_{12} & \dots  & B_{1m} \\
			B_{21} & B_{22} & \dots  & B_{2m} \\
			\vdots & \vdots & \ddots & \vdots \\
			B_{n1} & B_{n2} & \dots  & B_{nm}
		\end{pmatrix}\]

	the \textbf{Frobenius inner product} is defined as,

	\[\lr{A, B}_\F = \sum_{i,j}\overline{A_{ij}}B_{ij} = \text{tr}(A^*A)\]

	Where the overline denotes the complex conjugate, and $A^*$ denotes the conjugate transpose (\autoref{Conjugate Transpose}). Explicitly this sum is

	\[\begin{aligned}
		\lr{A,B}_\F = & \overline{A_{11}}B_{11} + \overline{A_{12}}B_{12} + \dots + \overline{A_{1m}}B_{1m}   \\
		              & + \overline{A_{21}}B_{21} + \overline{A_{22}}B_{22} + \dots + \overline{A_{2m}}B_{2m} \\
		              & \vdots                                                                                \\
		              & + \overline{A_{n1}}B_{n1} + \overline{A_{n2}}B_{n2} + \dots + \overline{A_{nm}}B_{nm} \\
	\end{aligned}\]
\end{definition}

\begin{definition}
	\hfill\\
	A vector space $V$ over $\F$ endowed with a specific inner product is called an \textbf{inner product space}. If $\F=\C$, we call $V$ a \textbf{complex inner product space}, whereas if $\F = \R$, we call $V$ a \textbf{real inner product space}.
\end{definition}

\begin{notation}
	\hfill\\
	For the remainder of this chapter, $F^n$ denotes the inner product space with the standard inner product as defined in \autoref{Definition 6.2}. Likewise, $M_{n \times n}(F)$ denotes the inner product space with the Frobenius inner product as defined in \autoref{Definition 6.4}.
\end{notation}

\begin{theorem}\label{Theorem 6.1}
	\hfill\\
	Let $V$ be an inner product space. Then for $x,y,z \in V$ and $c \in \F$ the following statements are true.

	\begin{enumerate}
		\item $\lr{x, y+z} = \lr{x,y} + \lr{x,z}$.
		\item $\lr{x,cy} = \overline{c}\lr{x,y}$.
		\item $\lr{x,0} = \lr{0,x} = 0$.
		\item $\lr{x,x} = 0$ if and only if $x = 0$.
		\item If $\lr{x,y} = \lr{x,z}$ for all $x \in V$, then $y=z$.
	\end{enumerate}
\end{theorem}

\begin{remark}
	\hfill\\
	It should be observed that the (1) and (2) of \autoref{Theorem 6.1} show that the inner product is \textbf{conjugate linear} in the second component.
\end{remark}

\begin{definition}
	\hfill\\
	Let $V$ be an inner product space. For $x \in V$, we define the \textbf{norm} or \textbf{length} of $x$ by\\ $||x|| = \sqrt{\lr{x,x}}$.
\end{definition}

\begin{theorem}
	\hfill\\
	Let $V$ be an inner product space over $\F$. Then for all $x,y \in V$ and $c \in \F$, the following statements are true.

	\begin{enumerate}
		\item $||cx|| = |c|\cdot||x||$.
		\item $||x|| = 0$ if and only if $x = 0$. In any case, $||x|| \geq 0$.
		\item (Cauchy-Schwarz Inequality) $|\lr{x,y}| \leq ||x||\cdot||y||$.
		\item (Triangle Inequality) $||x + y|| \leq ||x|| + ||y||$.
	\end{enumerate}
\end{theorem}

\begin{definition}
	\hfill\\
	Let $V$ be an inner product space. Vectors $x$ and $y$ in $V$ are \textbf{orthogonal} (\textbf{perpendicular}) if $\lr{x,y} = 0$. A subset $S$ of $V$ is \textbf{orthogonal} if any two distinct vectors in $S$ are orthogonal. A vector $x$ in $V$ is a \textbf{unit vector} if $||x|| = 1$. Finally, a subset $S$ of $V$ is \textbf{orthonormal} if $S$ is orthogonal and consists entirely of unit vectors.\\

	Note that if $S = \{v_1, v_2, \dots\}$, then $S$ is orthonormal if and only if $\lr{v_i, v_j} = \delta_{ij}$, where $\delta_{ij}$ denotes the Kronecker delta. Also, observe that multiplying vectors by nonzero scalars does not affect their orthogonality and that if $x$ is any nonzero vector, then $(1/||x||)x$ is a unit vector. The process of multiplying a nonzero vector by the reciprocal of its length is called \textbf{normalizing}.
\end{definition}

\begin{lemma}[\textbf{Parallelogram Law}]
	\hfill\\
	Let $V$ be an inner product space. Then

	\[||x + y||^2 + ||x - y||^2 = 2||x||^2 + 2||y||^2\ \ \text{for all}\ x,y \in V\]
\end{lemma}

\begin{definition}
	\hfill\\
	Let $V$ be a vector space $\F$, where $\F$ is either $\R$ of $\C$. Regardless of whether $V$ is or is not an inner product space, we may still define a norm $||\cdot||$ as a real-values function on $V$ satisfying the following three conditions for all $x,y \in V$ and $a \in \F$:

	\begin{enumerate}
		\item $||x|| \geq 0$, and $||x|| = 0$ if and only if $x = 0$.
		\item $||ax|| = |a| \cdot ||x||$.
		\item $||x + y|| \leq ||x|| + ||y||$.
	\end{enumerate}
\end{definition}

\begin{definition}
	\hfill\\
	Let $||\cdot||$ be a norm on a vector space $V$, and define, for each ordered pair of vectors, the scalar $d(x, y) = ||x - y||$. This is called the \textbf{distance} between $x$ and $y$.
\end{definition}
